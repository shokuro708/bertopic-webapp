# BERTopicçµ±åˆç‰ˆãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# BERTopicé–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from bertopic import BERTopic
    from sentence_transformers import SentenceTransformer
    from umap import UMAP
    from sklearn.feature_extraction.text import CountVectorizer
    BERTOPIC_AVAILABLE = True
except ImportError as e:
    BERTOPIC_AVAILABLE = False
    BERTOPIC_ERROR = str(e)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="BERTopic ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ” BERTopic ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª")
if BERTOPIC_AVAILABLE:
    st.markdown("**BERTopicå¯¾å¿œç‰ˆ** - é«˜åº¦ãªãƒˆãƒ”ãƒƒã‚¯åˆ†æãŒå¯èƒ½ã§ã™ï¼")
else:
    st.warning(f"âš ï¸ BERTopicãŒåˆ©ç”¨ã§ãã¾ã›ã‚“: {BERTOPIC_ERROR}")
    st.markdown("**è»½é‡ç‰ˆãƒ¢ãƒ¼ãƒ‰** - åŸºæœ¬çš„ãªåˆ†æã®ã¿åˆ©ç”¨å¯èƒ½")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")

# åˆ†ææ‰‹æ³•é¸æŠ
if BERTOPIC_AVAILABLE:
    analysis_method = st.sidebar.selectbox(
        "åˆ†ææ‰‹æ³•",
        ["BERTopicï¼ˆæ¨å¥¨ï¼‰", "è»½é‡ç‰ˆï¼ˆK-meansï¼‰"],
        help="BERTopicã¯é«˜ç²¾åº¦ã€è»½é‡ç‰ˆã¯é«˜é€Ÿ"
    )
else:
    analysis_method = "è»½é‡ç‰ˆï¼ˆK-meansï¼‰"
    st.sidebar.info("BERTopicãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€è»½é‡ç‰ˆã‚’ä½¿ç”¨")

# å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
if analysis_method == "BERTopicï¼ˆæ¨å¥¨ï¼‰":
    n_topics = st.sidebar.selectbox(
        "ãƒˆãƒ”ãƒƒã‚¯æ•°",
        ["è‡ªå‹•æ¤œå‡º"] + list(range(5, 51, 5)),
        help="è‡ªå‹•æ¤œå‡ºã‚’æ¨å¥¨"
    )
    min_topic_size = st.sidebar.slider("æœ€å°ãƒˆãƒ”ãƒƒã‚¯ã‚µã‚¤ã‚º", 5, 50, 10)
    language = st.sidebar.selectbox("è¨€èª", ["è‹±èª", "æ—¥æœ¬èª"])
else:
    n_clusters = st.sidebar.slider("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°", 2, 20, 5)
    max_features = st.sidebar.slider("æœ€å¤§ç‰¹å¾´æ•°", 50, 500, 100)
    min_df = st.sidebar.slider("æœ€å°æ–‡æ›¸é »åº¦", 1, 10, 2)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
tab1, tab2, tab3 = st.tabs(["ğŸ“¤ ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ğŸ“Š çµæœå¯è¦–åŒ–", "ğŸ“ˆ é«˜åº¦ãªåˆ†æ"])

with tab1:
    st.header("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
    )
    
    if uploaded_file is not None:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(), use_container_width=True)
            
            # åˆ—é¸æŠ
            col1, col2, col3 = st.columns(3)
            
            with col1:
                content_column = st.selectbox(
                    "åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆåˆ—",
                    df.columns.tolist(),
                    help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹åˆ—"
                )
            
            with col2:
                title_column = st.selectbox(
                    "ã‚¿ã‚¤ãƒˆãƒ«åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    ["ãªã—"] + df.columns.tolist(),
                    help="æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒå«ã¾ã‚Œã‚‹åˆ—"
                )
            
            with col3:
                timestamp_column = st.selectbox(
                    "æ™‚ç³»åˆ—åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    ["ãªã—"] + df.columns.tolist(),
                    help="å¹´ã‚„æ—¥ä»˜ã®æƒ…å ±ãŒã‚ã‚‹åˆ—"
                )
            
            # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œ", type="primary"):
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    status_text.text("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
                    progress_bar.progress(10)
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
                    texts = df[content_column].dropna().astype(str).tolist()
                    
                    # BERTopicåˆ†æ
                    if analysis_method == "BERTopicï¼ˆæ¨å¥¨ï¼‰" and BERTOPIC_AVAILABLE:
                        
                        min_cluster_size = max(min_topic_size, 2)
                        if len(texts) < min_cluster_size:
                            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ€ä½{min_cluster_size}ä»¶ã®æ–‡æ›¸ãŒå¿…è¦ã§ã™ã€‚")
                            st.stop()
                        
                        status_text.text("ğŸ¤– BERTopicãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ä¸­...")
                        progress_bar.progress(30)
                        
                        # BERTopicãƒ¢ãƒ‡ãƒ«è¨­å®š
                        if language == "è‹±èª":
                            embedding_model = SentenceTransformer('all-MiniLM-L6-v2')
                            vectorizer = CountVectorizer(stop_words="english", ngram_range=(1, 2))
                        else:
                            embedding_model = SentenceTransformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
                            vectorizer = CountVectorizer(ngram_range=(1, 2))
                        
                        umap_model = UMAP(n_components=5, random_state=42)
                        
                        topic_model = BERTopic(
                            embedding_model=embedding_model,
                            umap_model=umap_model,
                            vectorizer_model=vectorizer,
                            nr_topics=None if n_topics == "è‡ªå‹•æ¤œå‡º" else n_topics,
                            min_topic_size=min_topic_size,
                            calculate_probabilities=True,
                            verbose=False
                        )
                        
                        status_text.text("ğŸ“Š BERTopicãƒˆãƒ”ãƒƒã‚¯æŠ½å‡ºä¸­...")
                        progress_bar.progress(60)
                        
                        # ãƒˆãƒ”ãƒƒã‚¯æŠ½å‡º
                        topics, probs = topic_model.fit_transform(texts)
                        
                        status_text.text("ğŸ¨ çµæœå‡¦ç†ä¸­...")
                        progress_bar.progress(80)
                        
                        # çµæœã®æ•´ç†
                        topic_info = topic_model.get_topic_info()
                        
                        # 2Då¯è¦–åŒ–ç”¨ã®åº§æ¨™è¨ˆç®—
                        try:
                            umap_2d = UMAP(n_components=2, random_state=42)
                            embeddings = topic_model._extract_embeddings(texts)
                            coords_2d = umap_2d.fit_transform(embeddings)
                        except:
                            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: TF-IDFã‚’ä½¿ç”¨
                            vectorizer_fallback = TfidfVectorizer(max_features=100, stop_words='english')
                            tfidf_matrix = vectorizer_fallback.fit_transform(texts)
                            pca = PCA(n_components=2, random_state=42)
                            coords_2d = pca.fit_transform(tfidf_matrix.toarray())
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
                        st.session_state.bertopic_results = {
                            'method': 'BERTopic',
                            'topic_model': topic_model,
                            'topics': topics,
                            'probs': probs,
                            'topic_info': topic_info,
                            'coords_2d': coords_2d,
                            'texts': texts,
                            'df': df,
                            'content_column': content_column,
                            'title_column': title_column if title_column != "ãªã—" else None,
                            'timestamp_column': timestamp_column if timestamp_column != "ãªã—" else None
                        }
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… BERTopicåˆ†æå®Œäº†ï¼")
                        
                        st.success(f"ğŸ‰ BERTopicåˆ†æå®Œäº†ï¼{len(topic_info)}å€‹ã®ãƒˆãƒ”ãƒƒã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                        
                        # ãƒˆãƒ”ãƒƒã‚¯æ¦‚è¦è¡¨ç¤º
                        st.subheader("ğŸ“‹ ãƒˆãƒ”ãƒƒã‚¯æ¦‚è¦")
                        st.dataframe(topic_info, use_container_width=True)
                    
                    else:
                        # è»½é‡ç‰ˆåˆ†æï¼ˆK-meansï¼‰
                        if len(texts) < n_clusters:
                            st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ€ä½{n_clusters}ä»¶ã®æ–‡æ›¸ãŒå¿…è¦ã§ã™ã€‚")
                            st.stop()
                        
                        status_text.text("ğŸ”¤ ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
                        progress_bar.progress(40)
                        
                        # TF-IDF ãƒ™ã‚¯ãƒˆãƒ«åŒ–
                        vectorizer = TfidfVectorizer(
                            max_features=max_features,
                            stop_words='english',
                            ngram_range=(1, 2),
                            min_df=min_df
                        )
                        
                        tfidf_matrix = vectorizer.fit_transform(texts)
                        feature_names = vectorizer.get_feature_names_out()
                        
                        status_text.text("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
                        progress_bar.progress(70)
                        
                        # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
                        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                        clusters = kmeans.fit_predict(tfidf_matrix)
                        
                        status_text.text("ğŸ¨ å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
                        progress_bar.progress(90)
                        
                        # PCAã§2æ¬¡å…ƒã«æ¬¡å…ƒå‰Šæ¸›ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
                        pca = PCA(n_components=2, random_state=42)
                        coords_2d = pca.fit_transform(tfidf_matrix.toarray())
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
                        st.session_state.bertopic_results = {
                            'method': 'K-means',
                            'clusters': clusters,
                            'coords_2d': coords_2d,
                            'tfidf_matrix': tfidf_matrix,
                            'feature_names': feature_names,
                            'kmeans': kmeans,
                            'texts': texts,
                            'df': df,
                            'n_clusters': n_clusters
                        }
                        
                        progress_bar.progress(100)
                        status_text.text("âœ… è»½é‡ç‰ˆåˆ†æå®Œäº†ï¼")
                        
                        st.success(f"ğŸ‰ è»½é‡ç‰ˆåˆ†æå®Œäº†ï¼{n_clusters}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                    
                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    import traceback
                    st.text("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±:")
                    st.text(traceback.format_exc())
                    progress_bar.empty()
                    status_text.empty()
        
        except Exception as e:
            st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

with tab2:
    st.header("åˆ†æçµæœã®å¯è¦–åŒ–")
    
    if 'bertopic_results' in st.session_state:
        results = st.session_state.bertopic_results
        
        if results['method'] == 'BERTopic':
            # BERTopicçµæœã®å¯è¦–åŒ–
            st.subheader("ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ†å¸ƒ")
            
            # ãƒˆãƒ”ãƒƒã‚¯ã‚µã‚¤ã‚ºã®ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            topic_sizes = results['topic_info']['Count'].values
            topic_labels = [f"ãƒˆãƒ”ãƒƒã‚¯ {i}" for i in results['topic_info']['Topic'].values]
            
            fig_bar = px.bar(
                x=topic_labels,
                y=topic_sizes,
                title="å„ãƒˆãƒ”ãƒƒã‚¯ã®æ–‡æ›¸æ•°",
                labels={'x': 'ãƒˆãƒ”ãƒƒã‚¯', 'y': 'æ–‡æ›¸æ•°'}
            )
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # 2æ¬¡å…ƒæ•£å¸ƒå›³
            st.subheader("ğŸ—ºï¸ ãƒˆãƒ”ãƒƒã‚¯ãƒãƒƒãƒ—")
            
            scatter_df = pd.DataFrame({
                'x': results['coords_2d'][:, 0],
                'y': results['coords_2d'][:, 1],
                'topic': [f"ãƒˆãƒ”ãƒƒã‚¯ {t}" if t != -1 else "ãã®ä»–" for t in results['topics']],
                'text': [text[:100] + '...' if len(text) > 100 else text for text in results['texts']]
            })
            
            fig_scatter = px.scatter(
                scatter_df,
                x='x', y='y',
                color='topic',
                hover_data=['text'],
                title="æ–‡æ›¸ã®ãƒˆãƒ”ãƒƒã‚¯åˆ†å¸ƒãƒãƒƒãƒ—"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            
            # ãƒˆãƒ”ãƒƒã‚¯è©³ç´°
            st.subheader("ğŸ”¤ ãƒˆãƒ”ãƒƒã‚¯è©³ç´°")
            
            for _, row in results['topic_info'].iterrows():
                topic_id = row['Topic']
                if topic_id != -1:  # ãã®ä»–ãƒˆãƒ”ãƒƒã‚¯ã‚’é™¤ã
                    with st.expander(f"ãƒˆãƒ”ãƒƒã‚¯ {topic_id} - {row['Name']} ({row['Count']}ä»¶)"):
                        
                        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¡¨ç¤º
                        topic_words = results['topic_model'].get_topic(topic_id)
                        if topic_words:
                            keywords = [word for word, _ in topic_words[:10]]
                            st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(keywords)}")
                        
                        # ä»£è¡¨æ–‡æ›¸
                        topic_docs = [i for i, t in enumerate(results['topics']) if t == topic_id]
                        if topic_docs:
                            st.write("**ä»£è¡¨æ–‡æ›¸**:")
                            for i, doc_idx in enumerate(topic_docs[:3]):
                                if doc_idx < len(results['texts']):
                                    st.write(f"{i+1}. {results['texts'][doc_idx][:200]}...")
            
        else:
            # K-meansçµæœã®å¯è¦–åŒ–ï¼ˆå¾“æ¥é€šã‚Šï¼‰
            st.subheader("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒ")
            cluster_counts = pd.Series(results['clusters']).value_counts().sort_index()
            
            fig_bar = px.bar(
                x=[f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {i}" for i in cluster_counts.index],
                y=cluster_counts.values,
                title="å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ–‡æ›¸æ•°",
                labels={'x': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼', 'y': 'æ–‡æ›¸æ•°'}
            )
            st.plotly_chart(fig_bar, use_container_width=True)
            
            # 2æ¬¡å…ƒæ•£å¸ƒå›³
            st.subheader("ğŸ—ºï¸ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ–")
            
            scatter_df = pd.DataFrame({
                'x': results['coords_2d'][:, 0],
                'y': results['coords_2d'][:, 1],
                'cluster': [f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {c}" for c in results['clusters']],
                'text': [text[:100] + '...' if len(text) > 100 else text for text in results['texts']]
            })
            
            fig_scatter = px.scatter(
                scatter_df,
                x='x', y='y',
                color='cluster',
                hover_data=['text'],
                title="æ–‡æ›¸ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒ"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
        
        # çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        # çµæœãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        results_df = results['df'].copy()
        if results['method'] == 'BERTopic':
            results_df['topic'] = results['topics']
            results_df['topic_probability'] = [prob.max() if hasattr(prob, 'max') else prob for prob in results['probs']]
            results_df['topic_name'] = [f"ãƒˆãƒ”ãƒƒã‚¯ {t}" if t != -1 else "ãã®ä»–" for t in results['topics']]
        else:
            results_df['cluster'] = results['clusters']
            results_df['cluster_name'] = [f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {c}" for c in results['clusters']]
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv = results_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ åˆ†æçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name=f"{results['method'].lower()}_analysis_results.csv",
            mime="text/csv"
        )
        
    else:
        st.info("ğŸ‘† ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿åˆ†æã€ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

with tab3:
    st.header("é«˜åº¦ãªåˆ†ææ©Ÿèƒ½")
    
    if 'bertopic_results' in st.session_state and st.session_state.bertopic_results['method'] == 'BERTopic':
        results = st.session_state.bertopic_results
        
        # æ™‚ç³»åˆ—åˆ†æ
        if results['timestamp_column']:
            st.subheader("ğŸ“ˆ æ™‚ç³»åˆ—ãƒˆãƒ”ãƒƒã‚¯åˆ†æ")
            
            try:
                # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
                timestamps = results['df'][results['timestamp_column']].values
                topics_over_time = results['topic_model'].topics_over_time(
                    results['texts'], 
                    results['topics'], 
                    timestamps
                )
                
                # æ™‚ç³»åˆ—å¯è¦–åŒ–
                fig_timeline = results['topic_model'].visualize_topics_over_time(topics_over_time)
                st.plotly_chart(fig_timeline, use_container_width=True)
                
            except Exception as e:
                st.error(f"æ™‚ç³»åˆ—åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        # ãƒˆãƒ”ãƒƒã‚¯éšå±¤
        st.subheader("ğŸŒ³ ãƒˆãƒ”ãƒƒã‚¯éšå±¤åˆ†æ")
        
        if st.button("éšå±¤åˆ†æã‚’å®Ÿè¡Œ"):
            try:
                with st.spinner("éšå±¤åˆ†æã‚’å®Ÿè¡Œä¸­..."):
                    hierarchical_topics = results['topic_model'].hierarchical_topics(results['texts'])
                    fig_hierarchy = results['topic_model'].visualize_hierarchy(hierarchical_topics=hierarchical_topics)
                    st.plotly_chart(fig_hierarchy, use_container_width=True)
            except Exception as e:
                st.error(f"éšå±¤åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        
        # ãƒˆãƒ”ãƒƒã‚¯é¡ä¼¼åº¦
        st.subheader("ğŸ”— ãƒˆãƒ”ãƒƒã‚¯é¡ä¼¼åº¦ãƒãƒƒãƒ—")
        
        if st.button("é¡ä¼¼åº¦åˆ†æã‚’å®Ÿè¡Œ"):
            try:
                with st.spinner("é¡ä¼¼åº¦åˆ†æã‚’å®Ÿè¡Œä¸­..."):
                    fig_heatmap = results['topic_model'].visualize_heatmap()
                    st.plotly_chart(fig_heatmap, use_container_width=True)
            except Exception as e:
                st.error(f"é¡ä¼¼åº¦åˆ†æã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    else:
        st.info("é«˜åº¦ãªåˆ†ææ©Ÿèƒ½ã¯BERTopicåˆ†æçµæœã§ã®ã¿åˆ©ç”¨å¯èƒ½ã§ã™ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
if BERTOPIC_AVAILABLE:
    st.markdown("""
    **BERTopic ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª** 
    - é«˜åº¦ãªãƒˆãƒ”ãƒƒã‚¯ãƒ¢ãƒ‡ãƒªãƒ³ã‚°å¯¾å¿œ
    - æ™‚ç³»åˆ—åˆ†æãƒ»éšå±¤åˆ†ææ©Ÿèƒ½
    - å¤šè¨€èªå¯¾å¿œ
    """)
else:
    st.markdown("""
    **è»½é‡ç‰ˆãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª** 
    - TF-IDF + K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
    - BERTopicæ©Ÿèƒ½ã¯æº–å‚™ä¸­
    """)