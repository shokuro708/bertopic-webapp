# ç¢ºå®Ÿã«å‹•ãè»½é‡ç‰ˆãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="BERTopicé¢¨ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª",
    page_icon="ğŸ“Š",
    layout="wide"
)

st.title("ğŸ” BERTopicé¢¨ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª")
st.markdown("**PyTorchä¾å­˜ãªã—ã®è»½é‡ç‰ˆ** - ç¢ºå®Ÿã«å‹•ä½œã—ã¾ã™ï¼")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
st.sidebar.header("âš™ï¸ åˆ†æãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿")
n_clusters = st.sidebar.slider("ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼æ•°", 2, 20, 5)
max_features = st.sidebar.slider("æœ€å¤§ç‰¹å¾´æ•°", 50, 500, 100)
min_df = st.sidebar.slider("æœ€å°æ–‡æ›¸é »åº¦", 1, 10, 2)

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
tab1, tab2 = st.tabs(["ğŸ“¤ ãƒ‡ãƒ¼ã‚¿åˆ†æ", "ğŸ“Š çµæœå¯è¦–åŒ–"])

with tab1:
    st.header("CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    
    uploaded_file = st.file_uploader(
        "CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        type=['csv'],
        help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«"
    )
    
    if uploaded_file is not None:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
            df = pd.read_csv(uploaded_file, encoding='utf-8-sig')
            st.success(f"âœ… ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}è¡Œ")
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            st.subheader("ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.dataframe(df.head(), use_container_width=True)
            
            # åˆ—é¸æŠ
            col1, col2 = st.columns(2)
            
            with col1:
                content_column = st.selectbox(
                    "åˆ†æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆåˆ—",
                    df.columns.tolist(),
                    help="åˆ†æã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆãŒå«ã¾ã‚Œã‚‹åˆ—"
                )
            
            with col2:
                title_column = st.selectbox(
                    "ã‚¿ã‚¤ãƒˆãƒ«åˆ—ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰",
                    ["ãªã—"] + df.columns.tolist(),
                    help="æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«ãŒå«ã¾ã‚Œã‚‹åˆ—"
                )
            
            # åˆ†æå®Ÿè¡Œãƒœã‚¿ãƒ³
            if st.button("ğŸš€ ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚’å®Ÿè¡Œ", type="primary"):
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                try:
                    status_text.text("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ä¸­...")
                    progress_bar.progress(20)
                    
                    # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å–å¾—
                    texts = df[content_column].dropna().astype(str).tolist()
                    
                    if len(texts) < n_clusters:
                        st.error(f"âŒ ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ€ä½{n_clusters}ä»¶ã®æ–‡æ›¸ãŒå¿…è¦ã§ã™ã€‚")
                        st.stop()
                    
                    status_text.text("ğŸ”¤ ãƒ†ã‚­ã‚¹ãƒˆãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­...")
                    progress_bar.progress(40)
                    
                    # TF-IDF ãƒ™ã‚¯ãƒˆãƒ«åŒ–
                    vectorizer = TfidfVectorizer(
                        max_features=max_features,
                        stop_words='english',
                        ngram_range=(1, 2),
                        min_df=min_df
                    )
                    
                    tfidf_matrix = vectorizer.fit_transform(texts)
                    feature_names = vectorizer.get_feature_names_out()
                    
                    status_text.text("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
                    progress_bar.progress(70)
                    
                    # K-meansã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                    clusters = kmeans.fit_predict(tfidf_matrix)
                    
                    status_text.text("ğŸ¨ å¯è¦–åŒ–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆä¸­...")
                    progress_bar.progress(90)
                    
                    # PCAã§2æ¬¡å…ƒã«æ¬¡å…ƒå‰Šæ¸›ï¼ˆå¯è¦–åŒ–ç”¨ï¼‰
                    pca = PCA(n_components=2, random_state=42)
                    coords_2d = pca.fit_transform(tfidf_matrix.toarray())
                    
                    progress_bar.progress(100)
                    status_text.text("âœ… åˆ†æå®Œäº†ï¼")
                    
                    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«çµæœã‚’ä¿å­˜
                    st.session_state.analysis_results = {
                        'clusters': clusters,
                        'coords_2d': coords_2d,
                        'tfidf_matrix': tfidf_matrix,
                        'feature_names': feature_names,
                        'kmeans': kmeans,
                        'texts': texts,
                        'df': df
                    }
                    
                    st.success(f"ğŸ‰ åˆ†æå®Œäº†ï¼{n_clusters}å€‹ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸ")
                    
                except Exception as e:
                    st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                    progress_bar.empty()
                    status_text.empty()
        
        except Exception as e:
            st.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")

with tab2:
    st.header("åˆ†æçµæœã®å¯è¦–åŒ–")
    
    if 'analysis_results' in st.session_state:
        results = st.session_state.analysis_results
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒ
        st.subheader("ğŸ“Š ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒ")
        cluster_counts = pd.Series(results['clusters']).value_counts().sort_index()
        
        fig_bar = px.bar(
            x=[f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {i}" for i in cluster_counts.index],
            y=cluster_counts.values,
            title="å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®æ–‡æ›¸æ•°",
            labels={'x': 'ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼', 'y': 'æ–‡æ›¸æ•°'}
        )
        st.plotly_chart(fig_bar, use_container_width=True)
        
        # 2æ¬¡å…ƒæ•£å¸ƒå›³
        st.subheader("ğŸ—ºï¸ ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼å¯è¦–åŒ–ï¼ˆ2æ¬¡å…ƒãƒãƒƒãƒ—ï¼‰")
        
        scatter_df = pd.DataFrame({
            'x': results['coords_2d'][:, 0],
            'y': results['coords_2d'][:, 1],
            'cluster': [f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {c}" for c in results['clusters']],
            'text': [text[:100] + '...' if len(text) > 100 else text for text in results['texts']]
        })
        
        fig_scatter = px.scatter(
            scatter_df,
            x='x', y='y',
            color='cluster',
            hover_data=['text'],
            title="æ–‡æ›¸ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ†å¸ƒï¼ˆPCAæ¬¡å…ƒå‰Šæ¸›ï¼‰"
        )
        st.plotly_chart(fig_scatter, use_container_width=True)
        
        # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        st.subheader("ğŸ”¤ å„ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã®ç‰¹å¾´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰")
        
        for cluster_id in range(len(set(results['clusters']))):
            with st.expander(f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {cluster_id} ã®è©³ç´°"):
                cluster_docs = results['tfidf_matrix'][results['clusters'] == cluster_id]
                if cluster_docs.shape[0] > 0:
                    # ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ä¸­å¿ƒã®è¨ˆç®—
                    cluster_center = cluster_docs.mean(axis=0).A1
                    top_indices = cluster_center.argsort()[-15:][::-1]
                    top_words = [results['feature_names'][i] for i in top_indices]
                    
                    st.write(f"**ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(top_words)}")
                    st.write(f"**æ–‡æ›¸æ•°**: {cluster_docs.shape[0]}ä»¶")
                    
                    # ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸
                    sample_indices = np.where(results['clusters'] == cluster_id)[0][:3]
                    st.write("**ã‚µãƒ³ãƒ—ãƒ«æ–‡æ›¸**:")
                    for i, idx in enumerate(sample_indices):
                        if idx < len(results['texts']):
                            st.write(f"{i+1}. {results['texts'][idx][:200]}...")
        
        # çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.subheader("ğŸ’¾ çµæœãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
        
        # çµæœãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
        results_df = results['df'].copy()
        results_df['cluster'] = results['clusters']
        results_df['cluster_name'] = [f"ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ {c}" for c in results['clusters']]
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        csv = results_df.to_csv(index=False, encoding='utf-8-sig')
        st.download_button(
            label="ğŸ“¥ åˆ†æçµæœã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="text_analysis_results.csv",
            mime="text/csv"
        )
        
    else:
        st.info("ğŸ‘† ã¾ãšã€Œãƒ‡ãƒ¼ã‚¿åˆ†æã€ã‚¿ãƒ–ã§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã€åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
**è»½é‡ç‰ˆãƒ†ã‚­ã‚¹ãƒˆåˆ†æã‚¢ãƒ—ãƒª** 
- TF-IDF + K-means ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ä½¿ç”¨
- PyTorchä¸è¦ã§é«˜é€Ÿå‹•ä½œ
- BERTopicç‰ˆã¯æº–å‚™ä¸­
""")